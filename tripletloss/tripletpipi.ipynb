{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sx9e_pXlCuti",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "mean, std = 0.1307, 0.3081\n",
    "\n",
    "mnist_train_dataset = MNIST('../data/MNIST', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "                             ]))\n",
    "mnist_test_dataset = MNIST('../data/MNIST', train=False, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((mean,), (std,))\n",
    "                            ]))\n",
    "n_classes = 10\n",
    "\n",
    "# mnist_train_dataset.train_labels.item()\n",
    "# [boat, boat, ... , nature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AQSHPH9P0BNx"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "test_data_path = \"/notebooks/data/datasets/pipistrel/Hackathon/SingleFrame_ObjectProposalClassification/test\"\n",
    "train_data_path = \"/notebooks/data/datasets/pipistrel/Hackathon/SingleFrame_ObjectProposalClassification/train\"\n",
    "\n",
    "train_labels = os.path.join(train_data_path, \"/notebooks/userdata/teamE/TripletLoss/train_data_float.csv\")\n",
    "test_labels = os.path.join(test_data_path, \"/notebooks/userdata/teamE/TripletLoss/test_data_float.csv\")\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "def boats(root_path):\n",
    "    return os.path.join(root_path, \"boat\")\n",
    "\n",
    "def nature(root_path):\n",
    "    return os.path.join(root_path, \"nature\")\n",
    "\n",
    "def do_transform(image):\n",
    "    img_size_scaled = 64\n",
    "    transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.RandomHorizontalFlip(),\n",
    "                            torchvision.transforms.Resize(img_size_scaled),\n",
    "                            torchvision.transforms.CenterCrop(img_size_scaled),\n",
    "                            torchvision.transforms.ToTensor()\n",
    "                            ])\n",
    "    return transform(image)\n",
    "        \n",
    "    \n",
    "    \n",
    "class TripletPipi(data.Dataset):\n",
    "    \"\"\"\n",
    "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
    "    Test: Creates fixed triplets for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train=True):\n",
    "        self.train = train\n",
    "        self.extensions = ['png']\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = torch.Tensor([1 for _ in range(1011)] + [0 for _ in range(10379)])\n",
    "            self.train_data = [os.path.join(boats(train_data_path), file) \\\n",
    "                               for file in os.listdir(boats(train_data_path)) \\\n",
    "                               if file[-3:] in self.extensions] \\\n",
    "            + [os.path.join(nature(train_data_path), file) \\\n",
    "                                for file in os.listdir(nature(train_data_path)) \\\n",
    "                                if file[-3:] in self.extensions]\n",
    "            self.labels_set = set(np.array(self.train_labels))\n",
    "            self.label_to_indices = {label: np.where(np.array(self.train_labels) == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "        else:\n",
    "            self.test_labels = torch.Tensor([1 for _ in range(482)] + [0 for _ in range(4132)])\n",
    "            self.test_data = [os.path.join(boats(test_data_path), file) \\\n",
    "                                           for file in os.listdir(boats(test_data_path)) \\\n",
    "                                           if file[-3:] in self.extensions] \\\n",
    "                + [os.path.join(nature(test_data_path), file) \\\n",
    "                                for file in os.listdir(nature(test_data_path)) \\\n",
    "                                if file[-3:] in self.extensions]\n",
    "            # generate fixed triplets for testing\n",
    "            self.labels_set = set(np.array(self.test_labels))\n",
    "            self.label_to_indices = {label: np.where(np.array(self.test_labels) == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            triplets = [[i,\n",
    "                         random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                         random_state.choice(self.label_to_indices[\n",
    "                                                 np.random.choice(\n",
    "                                                     list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                 )\n",
    "                                             ])\n",
    "                         ]\n",
    "                        for i in range(len(self.test_data))]\n",
    "            self.test_triplets = triplets\n",
    "            \n",
    "    def load_image(self, path):\n",
    "        image = Image.open(path).convert('L')\n",
    "        return do_transform(image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
    "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "            img2 = self.train_data[positive_index]\n",
    "            img3 = self.train_data[negative_index]\n",
    "        else:\n",
    "            img1 = self.test_data[self.test_triplets[index][0]]\n",
    "            img2 = self.test_data[self.test_triplets[index][1]]\n",
    "            img3 = self.test_data[self.test_triplets[index][2]]\n",
    "\n",
    "        img1 = self.load_image(img1)\n",
    "        img2 = self.load_image(img2)\n",
    "        img3 = self.load_image(img3)\n",
    "        return (img1, img2, img3), []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_labels) if self.train else len(self.test_labels)\n",
    "    \n",
    "train_dataset = TripletPipi(train=True)\n",
    "test_dataset = TripletPipi(train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Dz2xh66UCut5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"using cuda: {}\".format(cuda))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist_classes = ['0', '1']\n",
    "colors = ['#ff77b4', '#00ff0e']\n",
    "\n",
    "def plot_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(2):\n",
    "        inds = np.where(targets==i)[0]\n",
    "        plt.scatter(embeddings[inds,0], embeddings[inds,1], alpha=0.5, color=colors[i])\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    plt.legend(mnist_classes)\n",
    "\n",
    "def extract_embeddings(dataloader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), 128))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target\n",
    "            k += len(images)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbKXy6yQCuuu"
   },
   "source": [
    "# Triplet network\n",
    "We'll train a triplet network, that takes an anchor, positive (same class as anchor) and negative (different class than anchor) examples. The objective is to learn embeddings such that the anchor is closer to the positive example than it is to the negative example by some margin value.\n",
    "\n",
    "![alt text](images/anchor_negative_positive.png \"Source: FaceNet\")\n",
    "Source: [2] *Schroff, Florian, Dmitry Kalenichenko, and James Philbin. [Facenet: A unified embedding for face recognition and clustering.](https://arxiv.org/abs/1503.03832) CVPR 2015.*\n",
    "\n",
    "**Triplet loss**:   $L_{triplet}(x_a, x_p, x_n) = max(0, m +  \\lVert f(x_a)-f(x_p)\\rVert_2^2 - \\lVert f(x_a)-f(x_n)\\rVert_2^2$\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(nn.Conv2d(1, 32, 5), nn.PReLU(),\n",
    "                                     nn.MaxPool2d(2, stride=2),\n",
    "                                     nn.Conv2d(32, 64, 5), nn.PReLU(),\n",
    "                                     nn.Conv2d(64, 96, 5), nn.PReLU(),\n",
    "                                     nn.MaxPool2d(2, stride=2),\n",
    "                                     nn.Conv2d(96, 96, 3), nn.PReLU(),\n",
    "                                     nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(1536, 256),\n",
    "                                nn.PReLU(),\n",
    "                                nn.Linear(256, 256),\n",
    "                                nn.PReLU(),\n",
    "                                nn.Linear(256, 128)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.convnet(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jv4DvFucCuuu"
   },
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "# from datasets import TripletMNIST\n",
    "\n",
    "triplet_train_dataset = TripletPipi(train_dataset) # Returns triplets of images\n",
    "triplet_test_dataset = TripletPipi(test_dataset)\n",
    "batch_size = 256\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "# from networks import EmbeddingNet, TripletNet\n",
    "from networks import TripletNet\n",
    "from losses import TripletLoss\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EmbeddingNet()\n",
    "model = TripletNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2397
    },
    "colab_type": "code",
    "id": "Dj9AoYpsCuuz",
    "outputId": "70ff7e3d-4e0b-403c-9af1-41c51a4c808e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/11390 (0%)]\tLoss: 0.999918\n",
      "Epoch: 1/20. Train set: Average loss: 0.1006\n",
      "Epoch: 1/20. Validation set: Average loss: 0.0400\n",
      "Train: [0/11390 (0%)]\tLoss: 0.021853\n",
      "Epoch: 2/20. Train set: Average loss: 0.0343\n",
      "Epoch: 2/20. Validation set: Average loss: 0.0230\n",
      "Train: [0/11390 (0%)]\tLoss: 0.014530\n",
      "Epoch: 3/20. Train set: Average loss: 0.1188\n",
      "Epoch: 3/20. Validation set: Average loss: 0.0374\n",
      "Train: [0/11390 (0%)]\tLoss: 0.026615\n",
      "Epoch: 4/20. Train set: Average loss: 0.0845\n",
      "Epoch: 4/20. Validation set: Average loss: 0.0350\n",
      "Train: [0/11390 (0%)]\tLoss: 0.022667\n",
      "Epoch: 5/20. Train set: Average loss: 0.0315\n",
      "Epoch: 5/20. Validation set: Average loss: 0.0232\n",
      "Train: [0/11390 (0%)]\tLoss: 0.007957\n",
      "Epoch: 6/20. Train set: Average loss: 0.0225\n",
      "Epoch: 6/20. Validation set: Average loss: 0.0183\n",
      "Train: [0/11390 (0%)]\tLoss: 0.004047\n",
      "Epoch: 7/20. Train set: Average loss: 0.0297\n",
      "Epoch: 7/20. Validation set: Average loss: 0.0197\n",
      "Train: [0/11390 (0%)]\tLoss: 0.000612\n",
      "Epoch: 8/20. Train set: Average loss: 0.0172\n",
      "Epoch: 8/20. Validation set: Average loss: 0.0156\n",
      "Train: [0/11390 (0%)]\tLoss: 0.006704\n",
      "Epoch: 9/20. Train set: Average loss: 0.0159\n",
      "Epoch: 9/20. Validation set: Average loss: 0.0162\n",
      "Train: [0/11390 (0%)]\tLoss: 0.009689\n",
      "Epoch: 10/20. Train set: Average loss: 0.0139\n",
      "Epoch: 10/20. Validation set: Average loss: 0.0142\n",
      "Train: [0/11390 (0%)]\tLoss: 0.006578\n",
      "Epoch: 11/20. Train set: Average loss: 0.0148\n",
      "Epoch: 11/20. Validation set: Average loss: 0.0146\n",
      "Train: [0/11390 (0%)]\tLoss: 0.020413\n"
     ]
    }
   ],
   "source": [
    "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "id": "ysh4Ry7ZCuu_",
    "outputId": "4194cf1d-da83-452a-94d6-2cd4c31aca2a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FlatPipistrelDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, train=True):        \n",
    "        self.extensions = ['png']\n",
    "        data_path = train_data_path if train else test_data_path\n",
    "        self.data = [os.path.join(boats(data_path), file) for file in os.listdir(boats(data_path)) \\\n",
    "                                                          if file[-3:] in self.extensions] \\\n",
    "                  + [os.path.join(nature(data_path), file) for file in os.listdir(nature(data_path)) \\\n",
    "                                                           if file[-3:] in self.extensions]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.__getitem__(idx)\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        return do_transform(image), 1 if \"boat\" in img_name else 0\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return list(self)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(FlatPipistrelDataset(False), batch_size=batch_size, shuffle=False, **kwargs)\n",
    "val_embeddings_tl, val_labels_tl = extract_embeddings(test_loader, model)\n",
    "plot_embeddings(val_embeddings_tl, val_labels_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_dir = \"/notebooks/userdata/teamE/TripletLoss/models\"\n",
    "model_index = \"04\"\n",
    "\n",
    "out_model = os.path.join(model_dir, model_index + \"-triplet-pipi.model\")    \n",
    "torch.save(model, out_model)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(FlatPipistrelDataset(False), batch_size=batch_size, shuffle=False, **kwargs)\n",
    "train_loader = torch.utils.data.DataLoader(FlatPipistrelDataset(True), batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "test_embeddings, _ = extract_embeddings(test_loader, model)\n",
    "train_embeddings, _ = extract_embeddings(train_loader, model)\n",
    "\n",
    "out_embeddings = os.path.join(model_dir, model_index + \"-test-embeddings.pickle\")\n",
    "with open(out_embeddings, \"wb\") as f:\n",
    "    pickle.dump(list(zip(test_embeddings, test_dataset.test_data)), f)\n",
    "\n",
    "out_embeddings = os.path.join(model_dir, model_index + \"-train-embeddings.pickle\")\n",
    "with open(out_embeddings, \"wb\") as f:\n",
    "    pickle.dump(list(zip(train_embeddings, train_dataset.train_data)), f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Experiments_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
